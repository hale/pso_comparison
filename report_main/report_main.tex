\documentclass{csfourzero}

\author{Philip Hale}
\title{A comparison of developments in PSO from 1995 to 2013}

\usepackage[utf8]{inputenc} % allows UTF-8 in references
\usepackage{natbib} % support for alpha style
\usepackage{amsmath} % better rendering of formulae
\usepackage{graphicx} % graphics support
\usepackage{epstopdf} % eps support
\usepackage{siunitx} % easier to use and read standard form. E.g. \num{3e-2}
\sisetup{tight-spacing=true}

% multi figures on one line
\usepackage{caption}
\usepackage{subcaption}

% Sort-of chicago-style (humanities) inline references.
\bibliographystyle{alpha}

% aligns overrightarrows in math formulae
\newcommand{\rarrow}[1]{\overrightarrow{#1\vphantom{b}}}

\begin{document}

\maketitle

\section{Abstract}

This paper compares the gold-standard of Particle Swarm Optimization
(SPSO-2011) with a canonical PSO implementation that is similar to original
designs from 1995. The success of each algorithm is determined by its ability
to optimize 3 functions. We begin by introducing PSO and the differences
between the algorithms under test, and conclude by evaluating the extent to
which limitations of PSO have been addressed by the current standard.

\section{Introduction}

Particle Swarm Optimization is a comparatively new evolutionary computation
technique, having only been around since 1995.  Conceptually the algorithm
emulates a flock of birds circling a roost, resulting in  behaviour described
by the original paper as ``flying potential solutions through hyperspace,
accelerating toward `better' solutions''~\cite{Kennedy:1995bi}.

Since the algorithm is simple and competitive with more complex and mature
optimization techniques, it has been the subject of much study. Research has
been primarily concerned with avoiding the potential for the algorithm to
prematurely converge on a non-global minima, and increasing the speed at which
convergence occurs~\cite{vandenBergh:2002tk}.

In 2007~\cite{Bratton:2007hq}, and then again in 2011~\cite{Clerc:2012to}, a
Standard PSO (SPSO) was proposed in order to give future research a baseline
comparison. Prior to this date, much of the claimed improvements to PSO were
made by comparison with an outdated model of PSO that didn't reflect a fair
baseline. This made comparison between results difficult. The new standards
provide a benchmark that mean  ``if your brand new algorithm does not
significantly `beat' SPSO (on a difficult enough non-biased benchmark) you have
to improve it''~\cite{Clerc:2012to}.

This paper is split into several parts. The first section defines PSO in its
most fundamental form, as first proposed in~\cite{Kennedy:1995bi}. Next, two
variations of PSO are introduced, which form the basis of the rest of this
study. Specifying these variations also provides a means to catalogue a
chronology of PSO developments, with special attention given to the discoveries
that have made their way into today's standards. The subsequent sections consist
of outlining some speculative hypotheses and an experimental setup to test these
claims empirically. Finally the results of this experiment are analysed, and
some pointers are given to current trends in PSO research.

\section{Particle Swarm Optimization: Background}

\subsection{Original PSO}

PSO consists of a population of particles, where each particle represents a
candidate solution to the objective function.  The number of particles is
referred to as the swarm-size, and is notated by $S$.

The dimension of the search space $D$ determines the magnitude of the position
and velocity matrices for each particle. Formally, the $position$ and $velocity$
for the $i^{th}$ particle are denoted by
$\rarrow{X_i} = x_{i1}, x_{i2},\ldots,x_{iD}$ and
$\rarrow{V_i} = v_{i1}, v_{i2},\ldots,v_{iD}$ respectively.
Initialization takes place by giving each particle a random velocity and
position within the search space.

Each particle keeps track of the best position they have reached so far. This is
known as the $personal best$, and is represented by $\rarrow{P_i} = p_{i1}, p_{i2},\ldots,p_{iD}$.
The performance or `fitness' of a given position can be determined by evaluating
the objective function with the position values as input. After each iteration,
the global best $g$ is updated with the best position of all particles in the
swarm.

Each iteration of the algorithm updates each particle's velocity and position.
These are computed as follows:

\begin{equation} \label{eq:orig_v_update}
\rarrow{V}_i^{t+1} = \rarrow{V}_i^t + c_1 \rarrow{U}_1^t \circ (\rarrow{P}_i^t - \rarrow{X}_i^t) + c_2 \rarrow{U}^t_2 \circ (g^t - \rarrow{X}_i^t)
\end{equation}

\begin{equation} \label{eq:orig_p_update}
\rarrow{X}_i^{t+1} = \rarrow{X}_i^t + \rarrow{V}_i^{t+1}
\end{equation}

$t = 1, 2,\ldots,T$, where T is the number of iterations. $c_1$ and $c_2$ are
the $cognitive$ and $social$ weights used to control the bias between locally
optimized and globally optimized search. $\rarrow{U}_1$ and $\rarrow{U}_2$ are
random vectors in the range $[0,1]$, and $\circ$ denotes the Hadamard product,
also known as entrywise product, of the two matrices.

Variations of the PSO algorithm consist of changes in the initialization of the
swarm, modifications to the velocity and positional update functions. These
are explained in detail below in defining the two algorithms under test.

\subsection{Canonical PSO}

Early analysis of the original PSO algorithm revealed some limitations, chief
among them premature convergence~\cite{vandenBergh:2002tk} and a comparatively
slow convergence speed~\cite{Shi:1998kl}. Alterations to the original approach
were suggested, and since some of these advancements have been present for a
decade or more, they have been included in this specification of Canonical
PSO\@.

The modifications described below have the effect of changing the velocity
update equation to:

\begin{equation} \label{eq:canon_v_update}
\rarrow{V}_i^{t+1} = \omega \rarrow{V}_i^t + c_1 \rarrow{U}_1^t \circ (\rarrow{P}_i^t - \rarrow{X}_i^t) + c_2 \rarrow{U}^t_2 \circ (\rarrow{L}^t - \rarrow{X}_i^t)
\end{equation}

\subsubsection{Inertia Weight}

Upon closer examination of the original PSO update procedure, it can be seen
that the cognitive and social weight values determine whether the search-space
contracts towards a best-known minimum or expands to explore a new range of
solutions. Given this tradeoff, it makes sense to introduce a new parameter that
``plays the role of balancing the global search and local search''. This is
called the inertia weight~\cite{Shi:1998kl}. Empirical evidence has suggested
that a linear-decreasing inertia weight gives the best results, where the
initial linear weight of $0.9$ decreases to $0.4$ as the number of iterations
increases~\cite{Shi:1998jj}.

This introduces a new parameter $\omega$ to the velocity update equation, which
gives momentum to the current velocity.

\subsubsection{Local Best; Neighbourhoods}

The specification above describes $\text{global best}$ or $gbest$ PSO\@. This
has the unfortunate property of premature convergence. In fact, until Guaranteed
Convergence PSO was introduced~\cite{vandenBergh:2002tk}, the algorithm could
not even guarantee convergence on a local minima.

A solution was proposed in the form of local best or $lbest$ PSO, which groups
the particles into distinct neighbourhoods, each with their own best-so-far
position value~\cite{Suganthan:1999iv}. Instead of a globally-known best
solution, each neighbourhood has its own local-best position. Earlier versions
of PSO were characterised by using this $lbest$ variation, and so it has been
chosen for the comparison. The paper that first proposed $lbest$ PSO used
Eculidian distance to determine neighbourhood groupings.  Canonical PSO uses the
more popular and computationally cheaper ring topology, which creates
neighbourhoods based on the array index of the particle swarm
(figure~\ref{fig:ring_topology}).

This has the effect of changing the algorithm such that instead
of a global best $g$, the best-known position of a particle's neighbourhood is
represented by $\rarrow{L} = l_1, l_2,\ldots,l_D$.

\begin{figure}
  \centering
  \begin{subfigure}[b]{0.3\textwidth}
    \includegraphics[width=\textwidth]{global_best_topology.eps}
    \captionof{figure}{Global-best}
    \label{fig:global_best_topology}
  \end{subfigure}
  ~
  \begin{subfigure}[b]{0.3\textwidth}
    \includegraphics[width=\textwidth]{ring_topology.eps}
    \captionof{figure}{Ring}
    \label{fig:ring_topology}
  \end{subfigure}
  ~
  \begin{subfigure}[b]{0.3\textwidth}
    \includegraphics[width=\textwidth]{star_topology.eps}
    \captionof{figure}{Adaptive-random}
    \label{fig:adaptive_random_topology}
  \end{subfigure}
  \caption{Swarm Topologies}
  \label{fig:swarm_topology}
\end{figure}

\subsection{SPSO 2011}

The effect of the modifications below is a new velocity-update formula.
$H_i(\rarrow{G}_i^t,||\rarrow{G}_i^t - \rarrow{X}_i^t||)$ defines a
hypersphere.

\begin{equation}
  \rarrow{V}_i^{t+1} = \omega \rarrow{V}_i^t + H_i(\rarrow{G}_i^t,||\rarrow{G}_i^t - \rarrow{X}_i^t||) - \rarrow{X}_i^t
\end{equation}

\subsubsection{Initialisation Procedure}

Like Canonical PSO, the initial position of particles is randomised within the
search space. The velocity initialization is modified in order to address a
problem where randomised initial velocities would cause particles to exit the
search space~\cite{Helwig:2008bl}.The new initialization procedure for velocity
prevents this form happening, and is calculated like so:

\begin{equation}
  V_i^0 = U(D_{min} - X_i^d, D_{max} - X_i^d)
\end{equation}

In addition, the parameter values are normalised, which transforms the
search-space into a hypercube. This is in order to gain maximum benefit from the
new velocity update equation, which makes use of
hyperspheres~\cite{Clerc:2012to}.

\subsubsection{Neighbourhood Topology}

Like Canonical PSO, SPSO-2011 also supports neighbourhoods. However whereas
Canonical PSO groups neighbours in a ring
topology~(figure~\ref{fig:ring_topology}), SPSO-2011 implements adaptive-random
topology~(figure~\ref{fig:adaptive_random_topology}). This introduces
variability into the neighbourhoods, whereby the neighbourhood changes each
time the local-best score stays the same.

With the suggested parameters, this means each particle informs itself plus a
maximum of two other randomly selected particles. By implication each particle
can be informed by anything from just itself to every particle in the swarm,
since a particle can be chosen more than once. In other words, ``the information
of the location of the global best is only communicated to a subset of the
swarm, and the composition of this subset varies from iteration to
iteration''~\cite{Miranda:2007er}

\subsubsection{Velocity update equations}

SPSO-2011 addresses a long running concern in PSO, where functions that
have minimums on the axis of the search space are much easier to optimize. The
technique to address this requires using rotational invariance to perform the
calculation based on a point slightly skewed from the known positions. The
effect of this operation is a more uniform distribution of all next possible
positions, $DNPP$. See figure~\ref{fig:dnpp} for a graphical depiction of this
change in behaviour.  The process and its effects are explained more thoroughly
in~\cite{ZambranoBigiarini:2013dl}.

\begin{figure}
  \centering
  \begin{subfigure}[b]{0.4\textwidth}
    \includegraphics[width=\textwidth]{dnpp_canonical.png}
    \caption{Canonical PSO}
    \label{fig:dnpp_canonical}
  \end{subfigure}
  ~
  \begin{subfigure}[b]{0.4\textwidth}
    \includegraphics[width=\textwidth]{dnpp_spso11.png}
    \caption{SPSO-2011}
    \label{fig:dnpp_spso11}
  \end{subfigure}
  \caption{DNPP, adapted from~\cite{ZambranoBigiarini:2013dl}}
  \label{fig:dnpp}
\end{figure}

\subsubsection{Confinement} % aka velocity clamping

``When a particle `flies' outside the $[min_d ,max_d]$ range, each boundary of
the search space acts as an absorbing wall, modifying the position of the
particle to coincide with the reached boundary and resetting the particle's
velocity to zero.''~\cite{ZambranoBigiarini:2013dl}.

\section{Research Question}

SPSO is not meant to be outperform every flavour of PSO either generally or on a
subset of optimization targets~\cite{Bratton:2007hq}. More performant PSO
implementations exist, but the improvements are either still under scrutiny or
limited to certain classes of functions.

Comparing the contemporary baseline-performance of PSO with an implementation
that resembles PSO from the late nineties allows us to assess how far the field
has come, and to what extent some of PSO's earlier limitations are still
relevant.



\section{Experimental Design}


\subsection{Functions}

In order to overcome potential bias, the functions have been shifted such that
the particles are not initialized around the global
minimum~\cite{Monson:2005fn}.

Three objective functions widely used in optimizatin literature have been tested
against, the results of which appear below. Experiments have been carried out
first in 2 and then 20 dimensions.

A Sphere is the simplest of optimization targets, since there are no local
minimum `traps' that can result in premature convergence. The Rosenbrock
function is a widely test function in optimization. PSO was first tested against
it in~\cite{Shi:1999je} using an algorithm somewhat similar to the Canonical PSO
described here.  Finally, the Rastrigin function has been chosen due to its
popularity in the literature. It features a large number of local minimum
clustered around the global minimum.

Plots of the functions~\ref{fig:functions} are 2-dimensional, with the z-axis
representing the function evaluation or fitness value for the given (x,y)
positional coordinate.

\begin{figure}
  \centering
  \begin{subfigure}[b]{0.3\textwidth}
    \includegraphics[width=\textwidth]{../functions/sphere_shifted.eps}
    \caption{2D Sphere}
    \label{fig:sphere}
  \end{subfigure}
  ~
  \begin{subfigure}[b]{0.3\textwidth}
    \includegraphics[width=\textwidth]{../functions/rosenbrock_shifted.eps}
    \caption{2D Rosenbrock}
    \label{fig:rosenbrock}
  \end{subfigure}
  ~
  \begin{subfigure}[b]{0.3\textwidth}
    \includegraphics[width=\textwidth]{../functions/rastrigin_shifted.eps}
    \caption{2D Rastrigin}
    \label{fig:rastrigin}
  \end{subfigure}
  \caption{Optimization Functions}
  \label{fig:functions}
\end{figure}

\subsection{Parameter selection}

In addition to and as a result of the differences in approach outlined above,
SPSO-2011 and Canonical PSO have different parameters.  This section lists the
setup for each PSO variation.

Some parameters have been kept the same between the variations under test, for
two reasons. Firstly because some parameter values do not represent a
fundamental advancement of the algorithm, and so it makes sense to set them to
best known values. An example of this would be swarm size, since despite much
experimentation there is still no consensus on the best choice; varying the
swarm size would not reflect a development of PSO research. Secondly, to
minimise the number of variables thus providing a more valid comparison.

\subsubsection{Swarm size}

It is not currently known how to pick the optimal number of
particles~\cite{Trelea:2003dv}, so a medium value of 20 has been chosen.
Increasing the swarm size increases the success rate at the expense of function
evaluations. Since our stopping criteria in this simulation is a set number of
function evaluations, it is important that the swarm size remains constant for
both algorithms.

The maximum number of function evaluations is dependent on the number of
dimensions, which is in keeping with the literature.

\subsubsection{Stopping criteria}

For Rastrigin, Sphere and Rosenbrock the success criteria is \num{1e-04}. This
matches the competition requirements for CEC2013, and is the default
configuration from the SPS0-2011 MATLAB implementation.

\begin{table}
\centering
  \begin{tabular}{lll}
  \hline
                                & Canonical PSO         & SPSO-2011 \\ \hline
  Swarm size                    & 20                    & 20 \\
  Particles per neighbourhood   & 7                     & $\approx$ 7 \\
  Number of runs                & 25                    & 25 \\
  Maximum function evaluations  & $D(\num{1e+05})$      & $D(\num{1e+05})$ \\
  Inertia                       & $0.9 \rightarrow 0.4$ & $\frac{1}{2\log{2}} \approx 0.7213$ \\
  Cognitive weight              & 1.49618               & $\frac{1}{2} + \log{2} \approx 0.3466$ \\
  Social weight                 & 1.49618               & $\frac{1}{2} + \log{2} \approx 0.3466$ \\
  \end{tabular}
  \caption{Parameter selection for Canonical PSO and SPSO}
  \label{tab:parameters}
\end{table}

\section{Results}

\begin{table}
\centering
\begin{tabular}{lllll}
  \hline
                                 & Avg. Func. Evals. & Avg. Time      & Succ\% \\ \hline
  Sphere 2D (Canonical PSO)      & \num{7.03e+03}    & \num{9.13e-02} & 100    \\
  Sphere 2D (SPSO-2011)          & \num{9.87e+02}    & \num{5.77e-02} & 100    \\ \hline
  Rosenbrock 2D (Canonical PSO)  & \num{1.86e+04}    & \num{2.18e-01} & 100    \\
  Rosenbrock 2D (SPSO-2011)      & \num{1.59e+03}    & \num{8.57e-02} & 100    \\ \hline
  Rastrigin 2D (Canonical PSO)   & \num{9.14e+03}    & \num{1.12e-01} & 100    \\
  Rastrigin 2D (SPSO-2011)       & \num{1.62e+03}    & \num{9.42e-02} & 100    \\ \hline
  Sphere 20D (Canonical PSO)     & \num{2.58e+05}    & \num{2.66e+01} & 100    \\
  Sphere 20D (SPSO-2011)         & \num{5.12e+03}    & \num{9.74e-01} & 100    \\ \hline
  Rosenbrock 20D (Canonical PSO) & \num{1.51e+06}    & \num{2.21e+01} & 44     \\
  Rosenbrock 20D (SPSO-2011)     & \num{1.63e+06}    & \num{3.11e+02} & 84     \\ \hline
  Rastrigin 20D (Canonical PSO)  & \num{2.00e+06}    & \num{1.62e+01} & 0      \\
  Rastrigin 20D (SPSO-2011)      & \num{2.00e+06}    & \num{3.92e+02} & 0      \\
\end{tabular}
\caption{Summary}
\label{tab:additional_data}
\end{table}

\begin{table}
\footnotesize
\centering
\begin{tabular}{lllllll}
  \hline
                          & Min            & Q1             & Median         & Q3             & Max            & Std. Dev.      \\ \hline
  Sphere 2D (CPSO)        & \num{1.53e-07} & \num{1.89e-05} & \num{3.77e-05} & \num{6.90e-05} & \num{9.11e-05} & \num{2.99e-05} \\
  Sphere 2D (SPSO11)      & \num{4.86e-06} & \num{2.54e-05} & \num{4.79e-05} & \num{7.29e-05} & \num{9.84e-05} & \num{2.64e-05} \\ \hline
  Rosenbrock 2D (CPSO)    & \num{5.80e-06} & \num{3.88e-05} & \num{5.90e-05} & \num{8.57e-05} & \num{9.53e-05} & \num{2.86e-05} \\
  Rosenbrock 2D (SPSO11)  & \num{2.46e-06} & \num{1.94e-05} & \num{5.45e-05} & \num{8.68e-05} & \num{9.64e-05} & \num{3.41e-05} \\ \hline
  Rastrigin 2D (CPSO)     & \num{2.48e-07} & \num{2.49e-05} & \num{5.87e-05} & \num{8.68e-05} & \num{9.89e-05} & \num{3.18e-05} \\
  Rastrigin 2D (SPSO11)   & \num{7.57e-06} & \num{4.33e-05} & \num{6.31e-05} & \num{8.59e-05} & \num{9.97e-05} & \num{2.94e-05} \\ \hline
  Sphere 20D (CPSO)       & \num{7.29e-05} & \num{8.72e-05} & \num{9.41e-05} & \num{9.82e-05} & \num{9.99e-05} & \num{7.32e-06} \\
  Sphere 20D (SPSO11)     & \num{7.26e-05} & \num{8.88e-05} & \num{9.19e-05} & \num{9.56e-05} & \num{9.95e-05} & \num{5.84e-06} \\ \hline
  Rosenbrock 20D (CPSO)   & \num{9.97e-06} & \num{1.00e-04} & \num{2.55e-02} & \num{3.99e+00} & \num{1.62e+01} & \num{3.50e+00} \\
  Rosenbrock 20D (SPSO11) & \num{9.99e-05} & \num{9.99e-05} & \num{1.00e-04} & \num{1.00e-04} & \num{3.99e+00} & \num{1.49e+00} \\ \hline
  Rastrigin 20D (CPSO)    & \num{9.95e-01} & \num{6.72e+00} & \num{8.95e+00} & \num{1.49e+01} & \num{1.99e+01} & \num{5.09e+00} \\
  Rastrigin 20D (SPSO11)  & \num{1.19e+01} & \num{1.74e+01} & \num{2.01e+01} & \num{2.61e+01} & \num{1.02e+02} & \num{2.50e+01} \\
\end{tabular}
\caption{Fitness Scores}
\label{tab:fitness_scores}
\end{table}

\section{Analysis}

The null hypothesis 

%Provide explanations for the observations above.

Of the three functions tested, Sphere in both dimensions was predicted to be the
easiest and for PSO to optimize. % this plays out in the results...?



\section{Conclusion}

What has been learnt, analysis of the results and procedure, further research,
references to current and future work in PSO research.

\bibliography{pso_comparison}

\end{document}
