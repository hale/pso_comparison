\documentclass{csfourzero}

\author{Philip Hale}
\title{Evaluating Developments in Particle Swarm Optimization Research from
1995 to 2011}

%%%%%%%%%%%%%%
%% PACKAGES %%
%%%%%%%%%%%%%%

\usepackage[utf8]{inputenc} % allows UTF-8 in references
\usepackage{natbib}         % support for alpha style
\usepackage{amsmath}        % better rendering of formulae
\usepackage{graphicx}       % graphics support
\usepackage{epstopdf}       % eps support

% easier to use and read standard form. E.g. \num{3e-2}
\usepackage{siunitx}
\sisetup{tight-spacing=true}

% multi figures on one line
\usepackage{caption}
\usepackage{subcaption}

\usepackage{pgfplots}
\pgfplotsset{width=\textwidth,compat=1.8}
\usepgfplotslibrary{statistics}

%%%%%%%%%%%%%%
%% SETTINGS %%
%%%%%%%%%%%%%%

% Sort-of chicago-style (humanities) inline references.
\bibliographystyle{alpha}

% aligns overrightarrows in math formulae
\newcommand{\rarrow}[1]{\overrightarrow{#1\vphantom{b}}}

% permit subsubsections etc.
\setcounter{secnumdepth}{3}

\begin{document}

\maketitle

\section{Abstract}

This paper compares the gold-standard of Particle Swarm Optimization with an
original PSO implementation that is similar to designs proposed in the late
nineties.  The success of each algorithm is determined by its ability to
optimize six functions. We begin by introducing PSO and the two algorithms under
test and conclude by evaluating the extent to which historical limitations of
PSO have been addressed by the current standard.

\section{Introduction}

This paper is split into several parts. The first section defines PSO in its
most fundamental form, as first proposed in~\cite{Kennedy:1995bi}. Next, a
question is proposed asking whether developments of this initial specification
have improved its performance. Two variations of PSO are introduced in this
context, to create a comparison point between `then' and `now'. An experiment
is devised where these two PSO variants are tested against optimization
functions with the aim of evaluating their comparative performance. After the
resulting data is presented, the results of this experiment are analysed with
respect to our original question. Finally, some pointers are given to current
trends in PSO research.

\section{Background}

Particle Swarm Optimization (PSO) is a comparatively new evolutionary
computation technique, having only been around since 1995.  Conceptually the
algorithm emulates a flock of birds circling a roost, resulting in  behaviour
described by the original paper as ``flying potential solutions through
hyperspace, accelerating toward `better' solutions''~\cite{Kennedy:1995bi}.

PSO consists of a population of particles, where each particle represents a
candidate solution to the objective function.  The number of particles is
referred to as the swarm-size, and is notated by $S$.

The dimension of the search space $D$ determines the magnitude of the position
and velocity matrices for each particle. Formally, the position and velocity
for the $i^{th}$ particle are denoted by
$\rarrow{X_i} = x_{i1}, x_{i2},\ldots,x_{iD}$ and
$\rarrow{V_i} = v_{i1}, v_{i2},\ldots,v_{iD}$ respectively.
Initialization takes place by giving each particle a random velocity and
position within the search space.

The $fitness$ of a position is determined by evaluating the optimization
function with respect to the particles position. A particle's
$personal\;best$, represented by$\rarrow{P_i} = p_{i1}, p_{i2},\ldots,p_{iD}$,
is the location in its history that has the best fitness.\footnote{Comparison
of fitness values is dependent on the optimization target, but is typically
whichever is geometrically closer to the global minimum.} After each iteration,
the global best $g$ is updated with the best position of all particles in the
swarm.

Each iteration of the algorithm updates each particle's velocity and position.
These are computed as follows:~\cite{ZambranoBigiarini:2013dl}

\begin{equation} \label{eq:orig_v_update}
\rarrow{V}_i^{t+1} = \rarrow{V}_i^t + c_1 \rarrow{U}_1^t \circ (\rarrow{P}_i^t - \rarrow{X}_i^t) + c_2 \rarrow{U}^t_2 \circ (g^t - \rarrow{X}_i^t)
\end{equation}

\begin{equation} \label{eq:orig_p_update}
\rarrow{X}_i^{t+1} = \rarrow{X}_i^t + \rarrow{V}_i^{t+1}
\end{equation}

$t = 1, 2,\ldots,T$, where T is the number of iterations. $c_1$ and $c_2$ are
the $cognitive$ and $social$ weights used to control the bias between locally
optimized and globally optimized search. $\rarrow{U}_1$ and $\rarrow{U}_2$ are
random vectors in the range $[0,1]$, and $\circ$ denotes the Hadamard product,
also known as entrywise product, of the two matrices.

\section{Research Question}

This paper evaluates ten years of research in PSO development; the extent to
which research has improved the optimization capabilities of PSO across a wide
range of objective functions.

Over the years a wide gamut of creative techniques have been employed to
explore the potential of PSO\@. These range from performing the positional
calculations in Quantum rather than Newtonian space~\cite{Sun:2004kc} to
meta-optimization of the velocity weights by running another PSO loop within
the velocity update equations~\cite{Schoene:2012ir}. Research has been
primarily concerned with avoiding the potential for the algorithm to
prematurely converge on non-global minima, and increasing the speed at which
convergence occurs~\cite{vandenBergh:2002tk}.

In 2007~\cite{Bratton:2007hq}, and then again in 2011~\cite{Clerc:2012to}, a
Standard PSO (SPSO) was proposed in order to give future research a baseline
comparison. Prior to this date, much of the claimed improvements to PSO were
made by comparison with outdated versions of PSO that didn't reflect a fair
baseline. This made comparison between results difficult. The new standards
provide a benchmark that mean  ``if your brand new algorithm does not
significantly `beat' SPSO (on a difficult enough non-biased benchmark) you have
to improve it''~\cite{Clerc:2012to}.

SPSO is not meant to be outperform every flavour of PSO either generally or on
a subset of optimization targets~\cite{Bratton:2007hq}. More performant PSO
implementations exist, but the improvements are either still under scrutiny or
limited to certain classes of functions. Comparing the contemporary
baseline-performance of PSO with early PSO allows us to assess how far the
field has come, and to what extent some of PSO's earlier limitations are still
present.

Therefore, in order to evaluate the progress in PSO development we compare
SPSO2011 to a basic, canonical PSO that approximates the state of PSO in the
early naughties. The following null hypotheses will be tested for both the
two-dimensional and twenty-dimensional cases.

\begin{enumerate}
  \item{There is no difference in convergence speed between an original PSO
      and a contemporary PSO.}
  \item{A contemporary PSO cannot converge closer to the global minimum
      than an original PSO.}
\end{enumerate}

\section{Algorithm Specifications}

\subsection{Canonical PSO}

Early analysis of the original PSO algorithm revealed some limitations, chief
among them premature convergence~\cite{vandenBergh:2002tk} and a comparatively
slow convergence speed~\cite{Shi:1998kl}. Alterations to the original approach
were suggested, and since some of these advancements have been present for a
decade or more, they have been included in this specification of Canonical
PSO\@.

\subsubsection{Inertia Weight}

Upon closer examination of the original PSO update procedure, it can be seen
that the cognitive and social weight values determine whether the search-space
contracts towards a best-known minimum or expands to explore a new range of
solutions. Given this tradeoff, it makes sense to introduce a new parameter that
``plays the role of balancing the global search and local search''. This is
called the inertia weight~\cite{Shi:1998kl}. Empirical evidence has suggested
that a linear-decreasing inertia weight gives the best results, where the
initial linear weight of $0.9$ decreases to $0.4$ as the number of iterations
increases~\cite{Shi:1998jj}.

This introduces a new parameter $\omega$ to the velocity update equation, which
gives momentum to the current velocity. The resulting equation is as follows:

\begin{equation} \label{eq:canon_v_update}
\rarrow{V}_i^{t+1} = \omega \rarrow{V}_i^t + c_1 \rarrow{U}_1^t \circ (\rarrow{P}_i^t - \rarrow{X}_i^t) + c_2 \rarrow{U}^t_2 \circ (\rarrow{L}^t - \rarrow{X}_i^t)
\end{equation}

\subsubsection{Local Best; Neighbourhoods}

The specification above describes $\text{global best}$ or $gbest$ PSO\@. This
has the unfortunate property of premature convergence. In fact, until Guaranteed
Convergence PSO was introduced~\cite{vandenBergh:2002tk}, the algorithm could
not even guarantee convergence on a local minima.

A solution was proposed in the form of local best or $lbest$ PSO, which groups
the particles into distinct neighbourhoods, each with their own best-so-far
position value~\cite{Suganthan:1999iv}. Instead of a globally-known best
solution, each neighbourhood has its own local-best position. Earlier versions
of PSO were characterised by using this $lbest$ variation, and so it has been
chosen for the comparison. The paper that first proposed $lbest$ PSO used
Euclidian distance to determine neighbourhood groupings.  Canonical PSO uses the
more popular and computationally cheaper ring topology, which creates
neighbourhoods based on the array index of the particle swarm
(figure~\ref{fig:ring_topology}).

This has the effect of changing the algorithm such that instead
of a global best $g$, the best-known position of a particle's neighbourhood is
represented by $\rarrow{L} = l_1, l_2,\ldots,l_D$.

\begin{figure}
  \centering
  \begin{subfigure}[b]{0.3\textwidth}
    \includegraphics[width=\textwidth]{global_best_topology.eps}
    \captionof{figure}{Global-best}
    \label{fig:global_best_topology}
  \end{subfigure}
  ~
  \begin{subfigure}[b]{0.3\textwidth}
    \includegraphics[width=\textwidth]{ring_topology.eps}
    \captionof{figure}{Ring}
    \label{fig:ring_topology}
  \end{subfigure}
  ~
  \begin{subfigure}[b]{0.3\textwidth}
    \includegraphics[width=\textwidth]{star_topology.eps}
    \captionof{figure}{Adaptive-random}
    \label{fig:adaptive_random_topology}
  \end{subfigure}
  \caption{Swarm Topologies}
  \label{fig:swarm_topology}
\end{figure}

\subsection{SPSO 2011}

\subsubsection{Initialisation Procedure}

Like Canonical PSO, the initial position of particles is randomised within the
search space. The velocity initialization is modified in order to address a
problem where randomised initial velocities would cause particles to exit the
search space~\cite{Helwig:2008bl}.The new initialization procedure for velocity
prevents this from happening, and is calculated like so:

\begin{equation}
  V_i^0 = U(D_{min} - X_i^d, D_{max} - X_i^d)
\end{equation}

In addition, the parameter values are normalised, which transforms the
search-space into a hypercube. This is in order to gain maximum benefit from the
new velocity update equation, which makes use of
hyperspheres~\cite{Clerc:2012to}.

\subsubsection{Neighbourhood Topology}

Like Canonical PSO, SPSO-2011 also supports neighbourhoods. However whereas
Canonical PSO groups neighbours in a ring
topology~(Figure~\ref{fig:ring_topology}), SPSO-2011 implements adaptive-random
topology~(Figure~\ref{fig:adaptive_random_topology}). This introduces
variability into the neighbourhoods, whereby the neighbourhood changes each
time the local-best score stays the same.

With the suggested parameters, this means each particle informs itself plus a
maximum of two other randomly selected particles. By implication each particle
can be informed by anything from just itself to every particle in the swarm,
since a particle can be chosen more than once. In other words, ``the information
of the location of the global best is only communicated to a subset of the
swarm, and the composition of this subset varies from iteration to
iteration''~\cite{Miranda:2007er}

\subsubsection{Velocity update equations}

SPSO-2011 addresses a long running concern in PSO, where functions that
have minimums on the axis of the search space are much easier to optimize. The
technique to address this requires using rotational invariance to perform the
calculation based on a point slightly skewed from the known positions. The
effect of this operation is a more uniform distribution of all next possible
positions, $DNPP$. See Figure~\ref{fig:dnpp} for a graphical depiction of this
change in behaviour.  The process and its effects are explained more thoroughly
in~\cite{ZambranoBigiarini:2013dl}.

\begin{figure}
  \centering
  \begin{subfigure}[b]{0.4\textwidth}
    \includegraphics[width=\textwidth]{dnpp_canonical.png}
    \caption{Canonical PSO}
    \label{fig:dnpp_canonical}
  \end{subfigure}
  ~
  \begin{subfigure}[b]{0.4\textwidth}
    \includegraphics[width=\textwidth]{dnpp_spso11.png}
    \caption{SPSO-2011}
    \label{fig:dnpp_spso11}
  \end{subfigure}
  \caption{DNPP, adapted from~\cite{ZambranoBigiarini:2013dl}}
  \label{fig:dnpp}
\end{figure}

The resulting new velocity-update formula is as follows, where
$H_i(\rarrow{G}_i^t,||\rarrow{G}_i^t - \rarrow{X}_i^t||)$ defines a hypersphere.

\begin{equation}
  \rarrow{V}_i^{t+1} = \omega \rarrow{V}_i^t + H_i(\rarrow{G}_i^t,||\rarrow{G}_i^t - \rarrow{X}_i^t||) - \rarrow{X}_i^t
\end{equation}

\subsubsection{Confinement} % aka velocity clamping

To prevent the particles from leaving the search-space, both the velocity and
the position of all particles is `clamped'. This is intended to increase the
speed of convergence since particles do not waste time initially heading in an
obviously wrong direction.

``When a particle `flies' outside the $[min_d ,max_d]$ range, each boundary of
the search space acts as an absorbing wall, modifying the position of the
particle to coincide with the reached boundary and resetting the particle's
velocity to zero.''~\cite{ZambranoBigiarini:2013dl}.

\section{Experimental Design}

The research question can be answered with empirical data gathered from running
implementations of PSO algorithms and comparing their performance.

Since Canonical PSO defined above lacks formal specification, it was clear that
the implementation chosen should allow for a large amount of customizability and
ease-of-use.  The MATLAB PSO Research Toolbox
(MPSORT)~\cite{MATLABPSOResearch:2011ux} is the most customizable PSO
implementation that could be found, and has the additional advantage of running
in MATLAB which makes it easy to plot and analyse results. Out of the box,
MPSORT comes configured somewhere between the two algorithms we are interested
in testing. With parameter adjustment it can model the Canonical PSO variant
described above.

Since SPSO2011 is a defined standard, it is important that the implementation
adheres to the specification. A number of PSO libraries claim SPSO
compatibility, but in order to reduce the difference between the two PSO
variants under test only MATLAB implementations were considered.
SPSO2011~\cite{SPSOMATLAB:zOjlExcK} has been chosen since it is a direct
translation of the initial C script, and has been developed by the authors of
the SPSO2011 spec.

Test runs were carried out on a Mac running OS X Mountain Lion, using
64bit MATLAB version 2013a. Each experiment was repeated 25 times to minimize
error.

\subsection{Functions}

Three objective functions have been chosen as optimization targets. Each
function might broadly be considered representative of an easy, medium and
difficult optimization problem. A twenty-dimensional version of each is also
included to provide a greater challenge.

The Sphere is the simplest of the three, since there are no local minimum
`traps' that can result in premature convergence. Rosenbrock is a widely used
test function in optimization; PSO was first tested against it
in~\cite{Shi:1999je} using an algorithm somewhat similar to the Canonical PSO
described here.  Rastrigin has been chosen due to its popularity as a
challenging target in optimization literature. It features a large number of
local minima clustered around the global minimum.

Plots of the functions (Figure~\ref{fig:functions}) are two-dimensional, with
the z-axis representing the function evaluation or fitness value for the given
(x,y) positional coordinate.

In order to overcome potential bias, the functions have been shifted such that
the particles are not initialized around the global
minimum~\cite{Monson:2005fn}.

The functions are considered minimized when the global minimum is found within
\num{1e-04}. This matches the competition requirements for CEC2013, and is the
default configuration from the SPS0-2011 MATLAB implementation.

\begin{figure}
  \centering
  \begin{subfigure}[b]{0.3\textwidth}
    \includegraphics[width=\textwidth]{../functions/sphere_shifted.eps}
    \caption{2D Sphere}
    \label{fig:sphere}
  \end{subfigure}
  ~
  \begin{subfigure}[b]{0.3\textwidth}
    \includegraphics[width=\textwidth]{../functions/rosenbrock_shifted.eps}
    \caption{2D Rosenbrock}
    \label{fig:rosenbrock}
  \end{subfigure}
  ~
  \begin{subfigure}[b]{0.3\textwidth}
    \includegraphics[width=\textwidth]{../functions/rastrigin_shifted.eps}
    \caption{2D Rastrigin}
    \label{fig:rastrigin}
  \end{subfigure}
  \caption{Optimization Functions}
  \label{fig:functions}
\end{figure}

\subsection{Parameter selection}

In addition to and as a result of the algorithmic differences outlined above,
SPSO-2011 and Canonical PSO have different parameters. Some parameters have
been kept the same between the variations under test, for two reasons. Firstly
because some parameter values do not represent a fundamental advancement of the
algorithm, and so it makes sense to set them to best known values.  Secondly,
to minimise the number of variables thus providing a more valid comparison.

Particles per neighbourhood is dictated by the $K$ value in SPSO2011, which
equates to a probable average of 7 when $k = 3$. Since Canonical PSO has a fixed
number of particles per neighbourhood, this has been set to precisely 7.

It is not currently known how to pick the optimal number of
particles~\cite{Trelea:2003dv}, so a medium value of 20 has been chosen.
Increasing the swarm size increases the success rate at the expense of function
evaluations. Since our stopping criteria in this simulation is a set number of
function evaluations, it is important that the swarm size remains constant for
both algorithms. The maximum number of function evaluations is dependent on the
number of dimensions, which is in keeping with the literature.

\begin{table}
\centering
  \begin{tabular}{lll}
  \hline
                                & Canonical PSO         & SPSO-2011 \\ \hline
  Swarm size                    & 20                    & 20 \\
  Particles per neighbourhood   & 7                     & $\approx$ 7 \\
  Number of runs                & 25                    & 25 \\
  Maximum function evaluations  & $D(\num{1e+05})$      & $D(\num{1e+05})$ \\
  Inertia                       & $0.9 \rightarrow 0.4$ & $\frac{1}{2\log{2}} \approx 0.7213$ \\
  Cognitive weight              & 1.49618               & $\frac{1}{2} + \log{2} \approx 0.3466$ \\
  Social weight                 & 1.49618               & $\frac{1}{2} + \log{2} \approx 0.3466$ \\
  \end{tabular}
  \caption{Parameter selection for Canonical PSO and SPSO}
  \label{tab:parameters}
\end{table}


\section{Results}

\subsection{Summary}

Table~\ref{tab:summary_data} reports summary results from the experiments. From
the success rates we can see that the global minimum was found in all
two-dimensional functions by both SPSO2011 and Canonical PSO\@. In addition, for
all trials both SPSO2011 and Canonical PSO were able to find the global minimum
of the sphere function in twenty dimensions. Looking at the Rosenbrock function
in 20 dimensions, we can see that Canonical PSO was able to find the global
minimum in 44\% of all trials. SPSO found the global minimum in twice as many
trials, 88\% of the total. Neither algorithm was able to find the global minimum
for the Rastrigin function in 20 dimensions.

For all functions except Rosenbrock and Rastrigin in 20 dimensions, SPSO2011
terminated around half an order of magnitude quicker wall-clock time than
Canonical PSO\@. In those two cases, SPSO2011 was in fact an order of magnitude
slower to terminate wall-clock time than Canonical PSO.

On average SPSO2011 terminated after an order of magnitude fewer function
evaluations than Canonical PSO, meaning it was quicker to converge on the global
minimum. Notably, SPSO-2011 was able to optimize the twenty-dimensional Sphere
function in approximately 50 times fewer function evaluations than Canonical
PSO\@. In the case of the twenty-dimensional Rastrigin function, both algorithms
terminated at the maximum number of function evaluations (\num{2e6}) before they
were able to find the global minimum.

\subsection{Fitness Scores}

Table~\ref{tab:fitness_scores} shows the results of statistical analysis on the
fitness scores for each function across all runs. The box plots
(Figures~\ref{fig:sphere_fitness},~\ref{fig:rosenbrock_fitness}~and~\ref{fig:rastrigin_fitness})
present these values graphically.

There is no significant difference between algorithms in the global fitness
achieved when optimizing the three 2D functions under test, and likewise for the
twenty-dimensional Sphere function.

This leaves 20D Rosenbrock and 20D Rastrigin. The box-plot for 20D Rosenbrock,
unlike the others, uses a logarithmic scale on the x-axis in order to display
the wide range of values. The maximum fitness value found for 20D Rosenbrock by
SPSO-2011 is not in fact an outlier since 16\% of the trials had an end global
fitness score of this order.  It can be said that when SPSO2011 finds the global
minimum of 20D Rosenbrock it is accurate, but when it doesn't it is incorrect by
a very wide margin of error. In comparison, Canonical PSO has a very broad
distribution of global fitness values for the 20D Rosenbrock function. Although
it was able to find the global minimum some of the time, the lower end of the
distrubution is much looser suggesting a decreased level of average accuracy.
The twenty-dimensional Rastrigin function shows that SPSO-2011 consistently
optimizes closer to the global minimum than Canonical PSO, although they are
both still a long way off the threshold for success in the majority of cases.

\begin{table}
\centering
\begin{tabular}{lllll}
  \hline
                                 & Avg. Func. Evals. & Avg. Time      & \% Success \\ \hline
  Sphere 2D (Canonical PSO)      & \num{7.03e+03}    & \num{9.13e-02} & 100    \\
  Sphere 2D (SPSO-2011)          & \num{9.87e+02}    & \num{5.77e-02} & 100    \\ \hline
  Rosenbrock 2D (Canonical PSO)  & \num{1.86e+04}    & \num{2.18e-01} & 100    \\
  Rosenbrock 2D (SPSO-2011)      & \num{1.59e+03}    & \num{8.57e-02} & 100    \\ \hline
  Rastrigin 2D (Canonical PSO)   & \num{9.14e+03}    & \num{1.12e-01} & 100    \\
  Rastrigin 2D (SPSO-2011)       & \num{1.62e+03}    & \num{9.42e-02} & 100    \\ \hline
  Sphere 20D (Canonical PSO)     & \num{2.58e+05}    & \num{2.66e+01} & 100    \\
  Sphere 20D (SPSO-2011)         & \num{5.12e+03}    & \num{9.74e-01} & 100    \\ \hline
  Rosenbrock 20D (Canonical PSO) & \num{1.51e+06}    & \num{2.21e+01} & 44     \\
  Rosenbrock 20D (SPSO-2011)     & \num{1.63e+06}    & \num{3.11e+02} & 84     \\ \hline
  Rastrigin 20D (Canonical PSO)  & \num{2.00e+06}    & \num{1.62e+01} & 0      \\
  Rastrigin 20D (SPSO-2011)      & \num{2.00e+06}    & \num{3.92e+02} & 0      \\
\end{tabular}
\caption{Summary}
\label{tab:summary_data}
\end{table}

\begin{table}
\footnotesize
\centering
\begin{tabular}{lllllll}
  \hline
                          & Min            & Q1             & Median         & Q3             & Max            & Std. Dev.      \\ \hline
  Sphere 2D (CPSO)        & \num{1.53e-07} & \num{1.89e-05} & \num{3.77e-05} & \num{6.90e-05} & \num{9.11e-05} & \num{2.99e-05} \\
  Sphere 2D (SPSO11)      & \num{4.86e-06} & \num{2.54e-05} & \num{4.79e-05} & \num{7.29e-05} & \num{9.84e-05} & \num{2.64e-05} \\ \hline
  Rosenbrock 2D (CPSO)    & \num{5.80e-06} & \num{3.88e-05} & \num{5.90e-05} & \num{8.57e-05} & \num{9.53e-05} & \num{2.86e-05} \\
  Rosenbrock 2D (SPSO11)  & \num{2.46e-06} & \num{1.94e-05} & \num{5.45e-05} & \num{8.68e-05} & \num{9.64e-05} & \num{3.41e-05} \\ \hline
  Rastrigin 2D (CPSO)     & \num{2.48e-07} & \num{2.49e-05} & \num{5.87e-05} & \num{8.68e-05} & \num{9.89e-05} & \num{3.18e-05} \\
  Rastrigin 2D (SPSO11)   & \num{7.57e-06} & \num{4.33e-05} & \num{6.31e-05} & \num{8.59e-05} & \num{9.97e-05} & \num{2.94e-05} \\ \hline
  Sphere 20D (CPSO)       & \num{7.29e-05} & \num{8.72e-05} & \num{9.41e-05} & \num{9.82e-05} & \num{9.99e-05} & \num{7.32e-06} \\
  Sphere 20D (SPSO11)     & \num{7.26e-05} & \num{8.88e-05} & \num{9.19e-05} & \num{9.56e-05} & \num{9.95e-05} & \num{5.84e-06} \\ \hline
  Rosenbrock 20D (CPSO)   & \num{9.97e-06} & \num{1.00e-04} & \num{2.55e-02} & \num{3.99e+00} & \num{1.62e+01} & \num{3.50e+00} \\
  Rosenbrock 20D (SPSO11) & \num{9.99e-05} & \num{9.99e-05} & \num{1.00e-04} & \num{1.00e-04} & \num{3.99e+00} & \num{1.49e+00} \\ \hline
  Rastrigin 20D (CPSO)    & \num{9.95e-01} & \num{6.72e+00} & \num{8.95e+00} & \num{1.49e+01} & \num{1.99e+01} & \num{5.09e+00} \\
  Rastrigin 20D (SPSO11)  & \num{1.19e+01} & \num{1.74e+01} & \num{2.01e+01} & \num{2.61e+01} & \num{1.02e+02} & \num{2.50e+01} \\
\end{tabular}
\caption{Fitness Scores}
\label{tab:fitness_scores}
\end{table}

\include{boxplots}

\section{Experimental Analysis}

The first thing to determine is whether or not Canonical PSO and SPSO-2011
are good models of an original PSO variant and a contemporary PSO variant
respectively. SPSO-2011 is the most recently available standard for
PSO, and its authors are well respected and frequently cited researchers of PSO.
The parameters described above that define the Canonical PSO variant are
indicative of simple PSO implementation that features some of the early
developments of PSO research in the algorithm's history. Therefore, it can be
said with some degree of certainty that comparing Canonical SPO and SPSO-2011
represents a comparison between early PSO research and recent developments.

The first null hypothesis is that there is no difference in convergence speed
between an original PSO and a contemporary PSO. Table~\ref{tab:summary_data}
clearly shows a statistically significant reduction in function evaluations
between Canonical SPO and SPSO-2011, in some cases as much as 50 times fewer for
SPSO-2011 when optimizing the same function. Therefore, the null hypothesis is
rejected in favour of a hypothesis that states contemporary PSO converges on the
global minimum in significantly fewer function evaluations than original PSO.

The second null hypothesis states that a contemporary PSO is not able to
converge closer to the global minimum than an original PSO\@. In this case, it is
useful to split this into two null hypotheses for each of the dimensions under
test. Taking the case of 2D functions, the data does not permit us to reject the
null hypotheses. Both algorithms performed equally well at optimising 2D
functions; there is no statistically significant difference between the two that
would lead us to believe there is a difference in convergence accuracy. The same
can be said of 20D Sphere function, since both are very good at optimising this
function. In the case of 20D Rosenbrock and 20D Rastrigin, there is some
evidence that supports rejecting the second null hypothesis in favour of a
hypothesis that states a contemporary PSO is marginally more accurate in
optimizing high-dimensional functions. This is not as strong a claim however,
because of the wide range of fitness readings for Rosenbrock and the inability
for either function to even come close to optimizing Rastrigin.

\section{Conclusion}

The results of experiments were less conclusive than might be anticipated.
Although we were able to conditionally reject the null hypotheses in some
situations, there was not strong evidence that SPSO-2011 is significantly better
at high-dimensionality function optimization than older and less advanced PSO
variants. Future research on a larger number of functions with varying swarm
sizes and dimensions would be needed to investigate if SPSO-2011 is more
consistent and scalable, since that is not something we were able to assess in
this paper.

Some areas of PSO research have been ignored in this study. For example, the
work that has been done in combining PSO with other nature-inspired algorithms.
The strength of PSO lies in the highly customizable nature of the fairly simple
algorithm.  Improvements to the fundamentals of PSO raises the bar, on top of
which bespoke optimization solutions can be written for a wide range of industry
applications. Therefore, it is promising that after several years of research
were were able to relatively easily prove a real improvement in baseline
performance.

\bibliography{pso_comparison}

\end{document}
